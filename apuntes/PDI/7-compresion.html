<!DOCTYPE html><html><head>
      <title>7-compresion</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////home/cubarro/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.8.19/crossnote/dependencies/katex/katex.min.css">
      
      
      <script type="text/javascript" src="file:////home/cubarro/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.8.19/crossnote/dependencies/mermaid/mermaid.min.js" charset="UTF-8"></script>
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h2 id="optimización-de-la-dimensionalidad-espectral-en-el-procesamiento-digital-de-imágenes-de-teledetección"><strong>Optimización de la Dimensionalidad Espectral en el Procesamiento Digital de Imágenes de Teledetección</strong> </h2>
<p><strong>Resumen</strong></p>
<p>El procesamiento y análisis de datos de teledetección multiespectrales o hiperespectrales exige estrategias rigurosas para gestionar la alta dimensionalidad y la redundancia inherente de la información (Richards y Jia 2006, 364). Este análisis académico se centra en tres metodologías fundamentales para la optimización de las características espectrales, comúnmente denominadas "comprensión de bandas": la <strong>Selección de Bandas</strong>, el <strong>Análisis de Componentes Principales (PCA, por sus siglas en inglés: Principal Components Analysis)</strong> y el <strong>Análisis de Componentes Canónicos (CCA, por sus siglas en inglés: Canonical Component Analysis)</strong> o Análisis Discriminante (Richards y Jia 2006, 364; 167; Jensen 2015, 361). Estas técnicas buscan sintetizar la información y maximizar la separabilidad entre clases temáticas, mejorando la eficiencia y precisión en la clasificación (Richards y Jia 2006, 364).</p>
<h3 id="introducción">Introducción </h3>
<p>La Geoinformación (o Geomática) es una disciplina en rápida expansión que integra técnicas para el estudio de la superficie terrestre, siendo la informática un componente decisivo (Gomarasca 2009, 2). La teledetección, al capturar datos multiespectrales o hiperespectrales, produce vastos volúmenes de datos que a menudo contienen redundancia espectral significativa (Richards y Jia 2006, 364).</p>
<p>La eficiencia económica de los procedimientos de clasificación digital, especialmente algoritmos como la Máxima Verosimilitud (<em>Maximum Likelihood</em>), está directamente relacionada con el número de "características" (bandas) utilizadas; el costo aumenta cuadráticamente con la dimensionalidad (Richards y Jia 2006, 364). Por lo tanto, la "comprensión de bandas" se convierte en un proceso esencial que se realiza mediante técnicas de reducción de características (<em>Feature Reduction</em>) (Richards y Jia 2006, 364). Estas técnicas permiten concentrar la información original en un número menor de bandas sintéticas, eliminando aquellas características que no contribuyen a la discriminación o separabilidad de las clases espectrales (Richards y Jia 2006, 364).</p>
<h3 id="1-selección-de-bandas-band-selection">1. Selección de Bandas (<em>Band Selection</em>) </h3>
<p>La selección de bandas es un proceso crucial que se lleva a cabo en la fase de entrenamiento de una clasificación supervisada (Jensen 2015, 361). El objetivo es identificar el subconjunto óptimo de bandas que maximice la discriminación entre las clases de interés (Richards y Jia 2006, 293).</p>
<h4 id="11-métodos-gráficos-espacios-de-características">1.1 Métodos Gráficos: Espacios de Características </h4>
<p>Un método fundamental para la selección de características es la visualización gráfica de los datos de entrenamiento en un espacio de vectores multiespectral (o espacio de características) (Jensen 2015, 360). En este espacio, cada píxel se representa como un punto cuyas coordenadas están dadas por su valor de brillo (<em>Digital Number</em>, DN) en cada componente espectral (Jensen 2015, 172).</p>
<p>Las <strong>parcelas cospectrales (o elipses)</strong> son herramientas gráficas que ilustran la separabilidad entre clases (Jensen 2015, 360). Estas parcelas utilizan la media (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mrow><mi>c</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mu_{ck}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) y la desviación estándar (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>c</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\sigma_{ck}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) de los datos de entrenamiento de cada clase <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span> en cada banda <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> para definir los límites de las clases. Si las parcelas (por ejemplo, paralelepípedos) de dos clases se superponen, esto indica que la combinación de bandas utilizada no es suficiente para distinguirlas (Jensen 2015, 360).</p>
<blockquote>
<p><strong>Figura 1. Visualización de Separabilidad en Espacio de Características</strong></p>
<p>Una ilustración de este método representaría un gráfico de dispersión bidimensional con las estadísticas de entrenamiento de las clases mostradas como paralelepípedos (Jensen 2015, 360). La superposición entre estas áreas demarca la confusión espectral, subrayando la necesidad de utilizar combinaciones de bandas que maximicen la distancia interclase (Jensen 2015, 360).</p>
</blockquote>
<h4 id="12-métodos-estadísticos-divergencia-transformada">1.2 Métodos Estadísticos: Divergencia Transformada </h4>
<p>Para cuantificar la separación estadística entre los patrones de respuesta espectral de pares de categorías, se utiliza la <strong>Divergencia Transformada (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>TDiver</mtext></mrow><annotation encoding="application/x-tex">\text{TDiver}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">TDiver</span></span></span></span></span>)</strong>, que es una distancia ponderada por covarianza entre las medias de las categorías (Jensen 2015, 361). Este es un criterio de selección de bandas que evalúa el grado de separabilidad entre clases (Jensen 2015, 361).</p>
<p>La <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>TDiver</mtext></mrow><annotation encoding="application/x-tex">\text{TDiver}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">TDiver</span></span></span></span></span> escala la divergencia a un rango de 0 a 2000 (Jensen 2015, 361). Un valor máximo (cercano a 2000) indica una gran "distancia estadística" entre los patrones de entrenamiento, lo que se traduce en una alta probabilidad de clasificación correcta (Jensen 2015, 361).</p>
<h3 id="2-análisis-de-componentes-principales-pca">2. Análisis de Componentes Principales (PCA) </h3>
<p>El <strong>Análisis de Componentes Principales (PCA)</strong>, o Transformada de Karhunen-Loève, es una herramienta de transformación multiespectral utilizada para la reducción de dimensionalidad y el realce de imágenes (Lillesand, Kiefer, y Chipman 2015, 500; Richards y Jia 2006, 141; Jensen 2015, 308). PCA se basa en la estadística global de la imagen y no está diseñado explícitamente para optimizar la estructura de clases (Richards y Jia 2006, 142).</p>
<h4 id="21-principios-y-mecanismo">2.1 Principios y Mecanismo </h4>
<p>PCA transforma matemáticamente las bandas originales (a menudo correlacionadas) en un nuevo conjunto de bandas (componentes principales) que no están correlacionadas entre sí (Lillesand, Kiefer, y Chipman 2015, 500; Richards y Jia 2006, 142). Esta transformación se logra mediante un análisis de los valores y vectores propios (<em>eigenanalysis</em>) de la matriz de covarianza de la imagen (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Σ</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">\Sigma_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) (Richards y Jia 2006, 165).</p>
<p>Los nuevos ejes de coordenadas se orientan de modo que la varianza de los datos sea máxima a lo largo del primer componente principal (PC1) (Lillesand, Kiefer, y Chipman 2015, 500). Los componentes subsiguientes explican cantidades decrecientes de la varianza total, siendo ortogonales entre sí (Lillesand, Kiefer, y Chipman 2015, 500). Debido a que es una simple rotación de ejes, los valores de brillo resultantes de los píxeles del PCA pueden ser negativos; esto se resuelve trasladando el origen del espacio de componentes principales para obtener componentes con valores de brillo positivos y, por lo tanto, visualizables (Richards y Jia 2006, 150–151).</p>
<blockquote>
<p><strong>Figura 2. Transformación de Componentes Principales</strong></p>
<p>Una representación de esta transformación mostraría un diagrama de dispersión de píxeles donde los ejes originales (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">X_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> y <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">X_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) son reemplazados por nuevos ejes rotados (PC1 y PC2) (Jensen 2015, 310; Lillesand, Kiefer, y Chipman 2015, 500). El Eje PC1 se extendería a través del eje semimayor de la distribución de los datos, capturando la mayor parte de la varianza total (Jensen 2015, 310).</p>
</blockquote>
<h4 id="22-aplicaciones-del-pca">2.2 Aplicaciones del PCA </h4>
<p>El PCA se utiliza en:</p>
<ol>
<li><strong>Realce de Imágenes y Visualización:</strong> Al asignar los primeros tres componentes principales a los primarios de color, se logra un uso eficiente del espacio de color disponible, aumentando el contraste y reduciendo la redundancia (Richards y Jia 2006, 151–152; Lillesand, Kiefer, y Chipman 2015, 500).</li>
<li><strong>Reducción de Dimensionalidad para Clasificación:</strong> El PCA es una técnica de reducción de características (<em>feature reduction</em>). Al reducir el conjunto de datos a la dimensionalidad intrínseca, se mejora la eficiencia del proceso computacional (Richards y Jia 2006, 154; Lillesand, Kiefer, y Chipman 2015, 528).</li>
<li><strong>Detección de Cambios:</strong> En datos multitemporales apilados, la información de cambio significativa a menudo se encuentra en los componentes principales de orden superior, conocidos como componentes de cambio (<em>change components</em>) (Jensen 2015, 526; Richards y Jia 2006, 166).</li>
</ol>
<h3 id="3-análisis-de-componentes-canónicos-cca">3. Análisis de Componentes Canónicos (CCA) </h3>
<p>A diferencia del PCA, que es un método no supervisado, el <strong>Análisis de Componentes Canónicos (CCA)</strong>, o <strong>Análisis Discriminante (AD)</strong>, es una transformación supervisada cuyo objetivo principal es maximizar la separación espectral entre las clases predefinidas por el analista (Jensen 2015, 361; Richards y Jia 2006, 167, 293).</p>
<h4 id="31-optimización-de-la-separabilidad-de-clases">3.1 Optimización de la Separabilidad de Clases </h4>
<p>El CCA es particularmente apropiado cuando se tiene conocimiento previo sobre las clases de interés. Esta técnica de transformación busca encontrar un nuevo eje de características que cumpla dos objetivos simultáneos (Richards y Jia 2006, 293):</p>
<ol>
<li>Maximizar la separación entre las medias de las clases (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">\sigma_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>).</li>
<li>Minimizar la dispersión de los datos dentro de cada clase (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mi>w</mi></msub></mrow><annotation encoding="application/x-tex">\sigma_w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>).</li>
</ol>
<p>El CCA logra una separación óptima al calcular la matriz de dispersión entre clases (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Σ</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">\Sigma_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) y la matriz de covarianza dentro de clases (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Σ</mi><mi>w</mi></msub></mrow><annotation encoding="application/x-tex">\Sigma_w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>). El criterio de optimización consiste en encontrar una matriz de transformación (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>) que maximice el ratio de la dispersión entre clases y la dispersión dentro de clases.</p>
<blockquote>
<p><strong>Figura 3. Comparación conceptual entre PCA y CCA</strong></p>
<p>Un esquema ilustraría la diferencia fundamental: los ejes del PCA (Ejes I y II) se definen por la máxima dispersión de <em>todos</em> los datos, sin considerar la identidad de la clase (Lillesand, Kiefer, y Chipman 2015, 500; Richards y Jia 2006, 293). En contraste, los ejes del CCA se definen para separar los grupos de píxeles etiquetados, maximizando la distancia entre las medias de los grupos, lo que lo hace explícitamente sensible a la estructura de la clase (Lillesand, Kiefer, y Chipman 2015, 500).</p>
</blockquote>
<h4 id="32-reducción-de-dimensionalidad-por-cca">3.2 Reducción de Dimensionalidad por CCA </h4>
<p>El CCA ofrece separabilidad con dimensionalidad reducida (Richards y Jia 2006, 180). Si hay <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> clases de interés y <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> bandas de datos multiespectrales, solo habrá <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">M-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> ejes canónicos no nulos (Richards y Jia 2006, 180). Por lo tanto, el CCA puede proporcionar la máxima separabilidad temática con una dimensionalidad inferior a la del PCA (Richards y Jia 2006, 180; 139).</p>
<p>La derivación de estos ejes transformados se conoce como <strong>Extracción de Características por Análisis Discriminante (DAFE)</strong> (Richards y Jia 2006, 293). El primer eje canónico (correspondiente al valor propio más grande, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span>) proporciona la máxima separación entre clases (Richards y Jia 2006, 180).</p>
<h3 id="conclusiones">Conclusiones </h3>
<p>Las metodologías de optimización de bandas—Selección de Bandas, <strong>PCA</strong> y <strong>CCA</strong>—son pilares en el análisis cuantitativo. La <strong>Selección de Bandas</strong> (cuantificada mediante la <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>TDiver</mtext></mrow><annotation encoding="application/x-tex">\text{TDiver}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">TDiver</span></span></span></span></span>) minimiza la redundancia (Jensen 2015, 361). El <strong>PCA</strong> ofrece una reducción de dimensionalidad robusta basada en la varianza global, ideal para el realce y la eficiencia computacional (Lillesand, Kiefer, y Chipman 2015, 500; Richards y Jia 2006, 154). Finalmente, el <strong>CCA</strong> proporciona una potente alternativa supervisada que optimiza explícitamente la separabilidad entre las clases de interés, incrementando potencialmente la precisión temática (Richards y Jia 2006, 180).</p>
<h2 id="infografía-optimización-espectral-para-análisis-de-imágenes">Infografía: Optimización Espectral para Análisis de Imágenes </h2>
<table>
<thead>
<tr>
<th style="text-align:left">Título Principal</th>
<th style="text-align:left"><strong>Optimización de la Dimensionalidad Espectral en Teledetección</strong> (Richards y Jia 2006, 364)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Objetivo Central</strong></td>
<td style="text-align:left">Reducir la redundancia de datos multiespectrales y maximizar la separabilidad entre clases temáticas (Richards y Jia 2006, 364).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Sección 1: Selección de Bandas (Filtrado de Características)</strong></td>
<td style="text-align:left"><strong>Propósito:</strong> Elegir las bandas originales más informativas (Jensen 2015, 361).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Criterio Gráfico</strong></td>
<td style="text-align:left"><strong>Espacio de Características:</strong> Visualiza la dispersión de píxeles (Jensen 2015, 360).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Criterio Estadístico</strong></td>
<td style="text-align:left"><strong>Divergencia Transformada (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>TDiver</mtext></mrow><annotation encoding="application/x-tex">\text{TDiver}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">TDiver</span></span></span></span></span>):</strong> Mide la distancia estadística entre pares de clases (rango 0–2000) (Jensen 2015, 361).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Sección 2: Análisis de Componentes Principales (PCA)</strong></td>
<td style="text-align:left"><strong>Propósito:</strong> Transformación <strong>no supervisada</strong> que captura la varianza de los datos en nuevos ejes ortogonales (Lillesand, Kiefer, y Chipman 2015, 500).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Mecanismo</strong></td>
<td style="text-align:left"><strong>Análisis de Varianza Global:</strong> Rota los ejes (PC1, PC2) para maximizar la dispersión total (Jensen 2015, 310).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Aplicaciones Clave</strong></td>
<td style="text-align:left">1. <strong>Reducción de Dimensionalidad</strong> (Richards y Jia 2006, 154). 2. <strong>Realce de Contraste</strong> (Richards y Jia 2006, 151).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Sección 3: Análisis de Componentes Canónicos (CCA)</strong></td>
<td style="text-align:left"><strong>Propósito:</strong> Transformación <strong>supervisada</strong> que optimiza la separabilidad de clases temáticas (Richards y Jia 2006, 167; 293).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Mecanismo</strong></td>
<td style="text-align:left"><strong>Análisis de Estructura de Clases:</strong> Maximiza la dispersión <em>entre</em> clases (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">\sigma_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) y minimiza la dispersión <em>dentro</em> de clases (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mi>w</mi></msub></mrow><annotation encoding="application/x-tex">\sigma_w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) (Richards y Jia 2006, 293).</td>
</tr>
<tr>
<td style="text-align:left"><strong>Resultado</strong></td>
<td style="text-align:left"><strong>Dimensionalidad Reducida Óptima:</strong> Genera hasta <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">M-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> ejes canónicos para <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> clases (Richards y Jia 2006, 180).</td>
</tr>
</tbody>
</table>
<h2 id="mapa-mental-comprensión-y-optimización-de-bandas-espectrales">Mapa Mental: Comprensión y Optimización de Bandas Espectrales </h2>
<p><a href="https://mermaid.live/edit#pako:eNqVVcFy2zYQ_RUMzqpLSpZk8aZQcmfSOvHYTg61Mpk1sJI3QwIcAHQte3zql2R6yiGnfILu6S91QUaS41ijVAeNKO6-9_DeAriXymqUmSzJ6BKqmREit2Xl0HhafTFiKV5XgUq6A9U8axQvwGjwYuorVMFBgV6ckboGpz2XvyQQ3SQZdERvcBjhhGi_c2sC3gYrLl-hQk8adET7Dv5dWyrEuAggJlRGGdZA0VT_Ks5Q10xuFEG2hzQSemaLq6kDw0eYTIxrxuS_VQ3arT4GUnY_0uurDxjoJlayALVxIgcHKqBbffYMBD4TxwihdtjWBebMfsqbcyxQPTX48pgK9lfbjSsTnJOhpi4T0wIX5ISvr5Q1H-q4qNWXaKaNGFcthnW0INNkdPmSzUTDAtJ-FJBuYE9Wn4LV1ovf2JE5O-LXb0RMOXr3_GqfICbbtlOIg1FgtfpcYYTmMDbjsrtxo2TqA-iW6LGaCd2gW2DMX1w4MH5uXQmah-GiefUDcrrtzR2xeOIQ30JhHTui0CkwzNakkjzX3LaPzepjQZ58YwMPlDU8RIxw6oi1VK2_p_l4Y-kFVUy0ldhm-8qK87pCd0O-Ef0HFdzJSXXE74RzdB0ekvyaqhLWKvrJ1hxkteRLBp4SmwCc6_KbqK__3O6YtHTQXwN8UxstOIHbZtc5NsMRmDv204a4Qf6fpjf-cTxnCIXC1iTDWfuAu1T108dtjzfVk12_E-Bwbzo5GMaMEyQu873hfJfMDiuHz2SxpZ-QV45t5WTiwifj4-kOpO6o90MoWz-24fz79_sxp81eolAF-Lh39gFyPx8Sm_6_WAjb4Zot_LMYL9DwUaPaSVlaJ_hCUNTeCAHL5tyE3TCyIxeOtMyCq7EjS2ST46O8jwQzGa6xxJnM-KfGOdRFmMmZeeC2Csyf1pbrTmfrxbXM5lB4fqorDQEnBAsH2xI0Gl1u-QCUWXrUQMjsXt7KrNvtHRz20mE_6R_1uqOk15FLmf1yeJAMB4NRb9Abpkf9_mj00JF3DWlyMGo_wyQdcc2Q4aAO9nxp1JoPNQXrTtpbs7k8H_4DgCNfSA">Editor</a></p>
<div class="mermaid">mindmap
  Comprensión y Optimización de Bandas Espectrales Richards y Jia 2006, 364
    
    Contexto [Necesidad de Optimización]
      Alta Dimensionalidad / Redundancia: Richards y Jia 2006, 364
      Costo Computacional: Aumento cuadrático: Richards y Jia 2006, 364
      Objetivo: Reducción de Características: Feature Reduction: Richards y Jia 2006, 364
    
    Selección de Bandas [Filtrado]
      Definición: Elegir subconjunto óptimo de bandas originales [Jensen 2015, 361]
      Métodos Gráficos
        Espacio de Características: Jensen 2015, 360
        Paralelepípedos Cospectrales: Jensen 2015, 360
      Métodos Estadísticos
        Divergencia Transformada: TDiver: Jensen 2015, 361
        Criterio: Valores cercanos a 2000: Jensen 2015, 361

    Análisis de Componentes Principales [PCA]
      Tipo: Transformación No Supervisada: Lillesand, Kiefer, y Chipman 2015, 500
      Mecanismo: Eigenanalysis de Σx: Richards y Jia 2006, 165
      Principio: Maximizar Varianza Total: Lillesand, Kiefer, y Chipman 2015, 500
      Usos
        Realce de Contraste: Richards y Jia 2006, 151
        Reducción de Dimensionalidad: Richards y Jia 2006, 154

    Análisis de Componentes Canónicos [CCA]
      Tipo: Transformación Supervisada: Richards y Jia 2006, 167
      Mecanismo: Análisis Discriminante: DAFE: Richards y Jia 2006, 293
      Principio
        Maximizar σ_A: Entre clases: Richards y Jia 2006, 293
        Minimizar σ_w: Dentro de clases: Richards y Jia 2006, 293
      Beneficio: Mayor precisión temática: Richards y Jia 2006, 293
</div>
      </div>
      
      
    
    
    <script type="module">
// TODO: If ZenUML gets integrated into mermaid in the future,
//      we can remove the following lines.


var MERMAID_CONFIG = ({"startOnLoad":false});
if (typeof MERMAID_CONFIG !== 'undefined') {
  MERMAID_CONFIG.startOnLoad = false
  MERMAID_CONFIG.cloneCssStyles = false
  MERMAID_CONFIG.theme = "default"
}

mermaid.initialize(MERMAID_CONFIG || {})
if (typeof(window['Reveal']) !== 'undefined') {
  function mermaidRevealHelper(event) {
    var currentSlide = event.currentSlide
    var diagrams = currentSlide.querySelectorAll('.mermaid')
    for (var i = 0; i < diagrams.length; i++) {
      var diagram = diagrams[i]
      if (!diagram.hasAttribute('data-processed')) {
        mermaid.init(null, diagram, ()=> {
          Reveal.slide(event.indexh, event.indexv)
        })
      }
    }
  }
  Reveal.addEventListener('slidetransitionend', mermaidRevealHelper)
  Reveal.addEventListener('ready', mermaidRevealHelper)
  await mermaid.run({
    nodes: document.querySelectorAll('.mermaid')
  })
} else {
  await mermaid.run({
    nodes: document.querySelectorAll('.mermaid')
  })
}
</script>
    
    
    
  
    </body></html>