{"extracted_information": "El contenido web proporciona un tutorial detallado sobre cómo manipular datos de video en tiempo real utilizando el elemento HTML `video` y `canvas` para aplicar efectos visuales. Se centra en la técnica de chroma-keying (efecto de pantalla verde) mediante código JavaScript, describiendo las técnicas de composición, el procesamiento de frames y la integración con el video.", "specifications": {"elementos_html_utilizados": ["video", "canvas (con IDs c1 y c2)"], "archivos_javascript": "processor.js", "dimensiones_procesamiento": "La mitad del ancho y alto original del video (video.videoWidth / 2, video.videoHeight / 2)", "umbral_color_chroma_key": {"green": "> 100", "red": "> 100", "blue": "< 43"}}, "pricing": {}, "features": [{"nombre": "Técnicas de Composición", "descripcion": "La técnica principal demostrada es el chroma-keying (pantalla verde). Implica copiar el frame de video actual a un primer canvas (`c1`), extraer sus datos de píxeles (`getImageData`), iterar sobre ellos para identificar y modificar los píxeles de la pantalla verde (estableciendo su canal alfa a 0 para hacerlos transparentes), y luego renderizar los datos modificados en un segundo canvas (`c2`) que ya contiene una imagen de fondo estática. Esto crea el efecto de superposición.", "metodos_clave": ["ctx.drawImage(videoElement, x, y, width, height)", "ctx.getImageData(x, y, width, height)", "ctx.putImageData(imageData, x, y)"]}, {"nombre": "Ejemplos Prácticos", "descripcion": "El artículo en sí es un ejemplo práctico completo de implementación de chroma-keying. Incluye el código HTML y JavaScript (`processor.js`) necesario para inicializar, procesar y mostrar el video con el efecto. Los ejemplos de código muestran la lógica de carga, la función de callback para el temporizador y la función de procesamiento de cada frame.", "ejemplo_codigo_principal": {"inicializacion": "processor.doLoad() al cargar el documento HTML, obtiene referencias a los elementos `video` y `canvas`, y configura un listener para el evento 'play' del video.", "bucle_procesamiento": "processor.timerCallback() se llama periódicamente (usando setTimeout(..., 0)) para ejecutar processor.computeFrame().", "procesamiento_frame": "processor.computeFrame() dibuja el frame de video, obtiene los datos de la imagen, itera y modifica los píxeles (configurando el alfa para chroma-key), y luego dibuja la imagen modificada en el canvas de salida."}}, {"nombre": "Procesamiento de Frames", "descripcion": "El procesamiento de frames se realiza en tiempo real. Cuando el video comienza a reproducirse, se inicia un bucle de procesamiento impulsado por `setTimeout`. Cada iteración del bucle ('timerCallback') llama a la función `computeFrame`, que es responsable de:", "pasos_procesamiento_frames": ["Dibujar el frame actual del elemento `video` en un `canvas` intermedio (`c1`) utilizando `ctx1.drawImage(this.video, ...)`. El frame se dibuja a la mitad del tamaño original del video.", "Obtener los datos de píxeles del `canvas` intermedio utilizando `ctx1.getImageData(...)`. Esto devuelve un objeto `ImageData` con los datos raw de 32 bits (RGBA) de cada píxel.", "Iterar sobre los datos de píxeles (cada 4 valores para RGBA) y aplicar lógica de chroma-key: si los valores de color de un píxel coinciden con los umbrales predefinidos de la pantalla verde, el valor de su canal alfa (`data[i + 3]`) se establece en 0 (totalmente transparente).", "Colocar los datos de píxeles modificados en el `canvas` de visualización final (`c2`) utilizando `ctx2.putImageData(...)`. Dado que `c2` ya puede tener una imagen de fondo precargada, los píxeles transparentes del video revelan el fondo."]}, {"nombre": "Integración con Video", "descripcion": "La integración se logra mediante el uso directo del elemento HTML `video` como fuente de frames para el `canvas`. El flujo de integración es el siguiente:", "mecanismos_integracion": ["Acceso al elemento `video`: El código JavaScript obtiene una referencia al elemento `video` por su ID (`document.getElementById('video')`).", "Escucha de eventos del `video`: Se adjunta un `EventListener` al elemento `video` para el evento 'play'. Esto asegura que el procesamiento de frames comience solo cuando el usuario inicia la reproducción.", "Dibujo directo del `video` en `canvas`: El método `ctx.drawImage()` puede aceptar directamente el elemento `video` como su primer argumento. Esto permite copiar el frame de video actual al contexto del `canvas` de manera eficiente.", "Sincronización de frames: El bucle de `timerCallback` se encarga de llamar `computeFrame` repetidamente, asegurando que cada frame del video que se está reproduciendo se procese y se muestre con el efecto en tiempo real."]}], "statistics": {}, "temporal_info": {}, "geographical_data": {}, "references": ["https://github.com/mdn/dom-examples/tree/main/canvas/chroma-keying", "https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/video", "https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/canvas", "https://developer.mozilla.org/en-US/docs/Web/Media", "https://developer.mozilla.org/en-US/docs/Web/Media/Guides/Formats", "https://developer.mozilla.org/en-US/docs/Learn_web_development/Core/Structuring_content/HTML_video_and_audio"]}